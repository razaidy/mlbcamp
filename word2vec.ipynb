{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of word2vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "F63zt4isCGtZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# A. Generating Word Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "WUSjdVwA7Mid",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. Generate the Word2Vec Embeddings**"
      ]
    },
    {
      "metadata": {
        "id": "zmSX2R__3WI4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "# define training data\n",
        "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
        "\t\t\t['this', 'is', 'the', 'second', 'sentence'],\n",
        "\t\t\t['yet', 'another', 'sentence'],\n",
        "\t\t\t['one', 'more', 'sentence'],\n",
        "\t\t\t['and', 'the', 'final', 'sentence']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YAkxipfm3sjf",
        "colab_type": "code",
        "outputId": "9856092e-c871-4147-8895-40cf124f89f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# train model\n",
        "model = Word2Vec(sentences, min_count=1)\n",
        "# summarize the loaded model\n",
        "print(model)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=14, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2B9KYVN630Yd",
        "colab_type": "code",
        "outputId": "095d4023-fe86-4fef-d587-796618ae1f4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# summarize vocabulary\n",
        "words = list(model.wv.vocab)\n",
        "print(words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec', 'second', 'yet', 'another', 'one', 'more', 'and', 'final']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FN5-itOx35QE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# access vector for one word\n",
        "print(model['sentence'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TYmKVLwC38Zu",
        "colab_type": "code",
        "outputId": "e449b40b-2f42-410d-e44a-a45ad6c5c03c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# save model\n",
        "model.save('model.bin')\n",
        "# load model\n",
        "new_model = Word2Vec.load('model.bin')\n",
        "print(new_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=14, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SRUW7D-r7BY7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Visualize the Embeddings**"
      ]
    },
    {
      "metadata": {
        "id": "9AspYHc15zyd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Retrieve the embeddings from the trained model\n",
        "X = model[model.wv.vocab]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WclevrNI8A8_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Train the pca prjection model using the scikit implementation of PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "result = pca.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F5UZeuL9-L7Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Plot the vectors using matplot\n",
        "from matplotlib import pyplot\n",
        "\n",
        "pyplot.scatter(result[:, 0], result[:, 1])\n",
        "words = list(model.wv.vocab)\n",
        "for i, word in enumerate(words):\n",
        "\tpyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O_uE_kSGCHwK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# B. Loading Pre-trained Embeddings"
      ]
    },
    {
      "metadata": {
        "id": "QbLqrHcYC3Tg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. Stanfordsâ€™s GloVe Embeddings**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RtBxrq-oOl4K",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "filename = 'GoogleNews-vectors-negative300.bin'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iqnjEesFNPK4",
        "colab_type": "code",
        "outputId": "52a2d74c-b9fe-4cc6-959c-75850c47bc1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "glove_input_file = 'glove.6.300d.txt'\n",
        "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "IFHwlSneN4db",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "# load the Stanford GloVe model\n",
        "filename = 'glove.6B.100d.txt.word2vec'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
        "# calculate: (king - man) + woman = ?\n",
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mXHNpenSOAD0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(model['queen'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}